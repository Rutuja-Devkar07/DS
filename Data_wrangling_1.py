# -*- coding: utf-8 -*-
"""DSBDA_PR1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KRT51tbL-j9o7Fmd0F0rG0-RrQ-sSUxW
"""
# 1) Data Wrangling, I
# Perform the following operations using Python on any open-source dataset (e.g., data.csv)
# 1. Import all the required Python Libraries.
# 2. Locate an open-source data from the web (e.g., https://www.kaggle.com). Provide a clear
# description of the data and its source (i.e., URL of the web site).
# 3. Load the Dataset into pandas dataframe.
# 4. Data Preprocessing: check for missing values in the data using pandas isnull (), describe ()
# function to get some initial statistics. Provide variable descriptions. Types of variables etc.
# Check the dimensions of the data frame.
# 5. Data Formatting and Data Normalization: Summarize the types of variables by checking
# the data types (i.e., character, numeric, integer, factor, and logical) of the variables in the
# data set. If variables are not in the correct data type, apply proper type conversions.
# 6. Turn categorical variables into quantitative variables in Python.
import pandas as pd

import numpy as np

df = pd.read_csv('IRIS.csv')

print(df.isnull().sum())

print(df.describe())

print(df.shape)

print(df.dtypes)

from sklearn.preprocessing import LabelEncoder

# Create LabelEncoder object
le = LabelEncoder()

# Fit and transform the 'Species' column
df['species_encoded'] = le.fit_transform(df['species'])


print(df[['species', 'species_encoded']].head())

print(df['species'].value_counts())
print(df['species_encoded'].value_counts())

print(df.sort_values('species_encoded')[['species', 'species_encoded']])

